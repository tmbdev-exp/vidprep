{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharding\n",
    "\n",
    "This is a small Jupyter notebook illustrating how to take a dataset in the cloud (or on disk) and turn it into a set of sharded tar archives.\n",
    "\n",
    "The process consists of two steps:\n",
    "\n",
    "- get a file listing of the original dataset and group it by related files\n",
    "- output one \"recipe\" for each shard that specifies where files come from and how they are stored in each .tar archive\n",
    "- apply `tarp create` to these recipes to create the actual shards\n",
    "\n",
    "The process of creating the \"recipes\" is serial but quick. The `tarp create` jobs can be run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "from itertools import groupby\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ident(s):\n",
    "    \"Reduce a pathname to the video identifier.\"\n",
    "    s = os.path.basename(s)\n",
    "    s = re.sub(r'[.].*$', '', s)\n",
    "    return s\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"Return an iterator over chunks of size n from the original iterator l.\"\n",
    "    result = []\n",
    "    for x in l:\n",
    "        if len(result) >= n:\n",
    "            yield result\n",
    "            result = []\n",
    "        result.append(x)\n",
    "    if result != []:\n",
    "        yield result\n",
    "\n",
    "def flatten(l):\n",
    "    \"Flatten an iterator of iterators into a list.\"\n",
    "    return [x for s in l for x in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of file names (we're just using aa* to keep the demo short)\n",
    "\n",
    "samples = sorted(\n",
    "    [s.strip() for s in os.popen(\"gsutil ls gs://lpr-yt8m/aa*\").readlines()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group into lists of samples with the same basename\n",
    "samples = [list(l[1]) for l in groupby(samples, ident)]\n",
    "\n",
    "# only keep samples that contain a \".mp4\"\n",
    "samples = [l for l in samples if any(s.endswith(\".mp4\") for s in l)]\n",
    "\n",
    "# chunk into groups of 100 samples\n",
    "shards = chunks(samples, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p shards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shard 0\n",
      "shard 1\n",
      "shard 2\n",
      "shard 3\n",
      "shard 4\n",
      "shard 5\n",
      "shard 6\n",
      "shard 7\n",
      "shard 8\n"
     ]
    }
   ],
   "source": [
    "# write into separate shard files\n",
    "\n",
    "for index, shard in enumerate(shards):\n",
    "    print(f\"shard {index}\")\n",
    "    shard = flatten(shard)\n",
    "    with open(f\"shards/shard-{index:06d}.txt\", \"w\") as stream:\n",
    "        for fname in shard:\n",
    "            base = os.path.basename(fname)\n",
    "            print(f\"{base}\\tpipe:curl https://storage.googleapis.com/lpr-yt8m/{base}\", file=stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shard-000000.tar  shard-000002.txt  shard-000005.txt  shard-000008.txt\n",
      "shard-000000.txt  shard-000003.txt  shard-000006.txt\n",
      "shard-000001.txt  shard-000004.txt  shard-000007.txt\n"
     ]
    }
   ],
   "source": [
    "!ls shards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Shards\n",
    "\n",
    "Each text file now contains an output file name (to be placed into the tar file) and a source file. \n",
    "\n",
    "The source file can either be a path, \"text:something\", in which case, \"something\" is literally placed into the tar file under the given path, or \"pipe:something\", in which case \"something\" is executed as a shell script and its stdout captured and stored in the output tar file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa-4wUIa9zE.annotations.xml\tpipe:curl https://storage.googleapis.com/lpr-yt8m/aa-4wUIa9zE.annotations.xml\n",
      "aa-4wUIa9zE.description\tpipe:curl https://storage.googleapis.com/lpr-yt8m/aa-4wUIa9zE.description\n",
      "aa-4wUIa9zE.dllog\tpipe:curl https://storage.googleapis.com/lpr-yt8m/aa-4wUIa9zE.dllog\n",
      "aa-4wUIa9zE.info.json\tpipe:curl https://storage.googleapis.com/lpr-yt8m/aa-4wUIa9zE.info.json\n",
      "aa-4wUIa9zE.mp4\tpipe:curl https://storage.googleapis.com/lpr-yt8m/aa-4wUIa9zE.mp4\n",
      "aa-Dmn0MZzI.annotations.xml\tpipe:curl https://storage.googleapis.com/lpr-yt8m/aa-Dmn0MZzI.annotations.xml\n",
      "aa-Dmn0MZzI.description\tpipe:curl https://storage.googleapis.com/lpr-yt8m/aa-Dmn0MZzI.description\n",
      "aa-Dmn0MZzI.dllog\tpipe:curl https://storage.googleapis.com/lpr-yt8m/aa-Dmn0MZzI.dllog\n",
      "aa-Dmn0MZzI.info.json\tpipe:curl https://storage.googleapis.com/lpr-yt8m/aa-Dmn0MZzI.info.json\n",
      "aa-Dmn0MZzI.mp4\tpipe:curl https://storage.googleapis.com/lpr-yt8m/aa-Dmn0MZzI.mp4\n"
     ]
    }
   ],
   "source": [
    "!head shards/shard-000000.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] 0 aa-4wUIa9zE.annotations.xml <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-4wUIa9zE.annotations.xml\n",
      "[info] 1 aa-4wUIa9zE.description <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-4wUIa9zE.description\n",
      "[info] 2 aa-4wUIa9zE.dllog <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-4wUIa9zE.dllog\n",
      "[info] 3 aa-4wUIa9zE.info.json <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-4wUIa9zE.info.json\n",
      "[info] 4 aa-4wUIa9zE.mp4 <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-4wUIa9zE.mp4\n",
      "[info] 5 aa-Dmn0MZzI.annotations.xml <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-Dmn0MZzI.annotations.xml\n",
      "[info] 6 aa-Dmn0MZzI.description <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-Dmn0MZzI.description\n",
      "[info] 7 aa-Dmn0MZzI.dllog <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-Dmn0MZzI.dllog\n",
      "[info] 8 aa-Dmn0MZzI.info.json <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-Dmn0MZzI.info.json\n",
      "[info] 9 aa-Dmn0MZzI.mp4 <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-Dmn0MZzI.mp4\n",
      "[info] 10 aa-NUmrbdhU.annotations.xml <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-NUmrbdhU.annotations.xml\n",
      "[info] 11 aa-NUmrbdhU.description <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-NUmrbdhU.description\n",
      "[info] 12 aa-NUmrbdhU.dllog <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-NUmrbdhU.dllog\n",
      "[info] 13 aa-NUmrbdhU.info.json <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-NUmrbdhU.info.json\n",
      "[info] 14 aa-NUmrbdhU.mp4 <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-NUmrbdhU.mp4\n",
      "[info] 15 aa-SLTMuWLc.annotations.xml <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-SLTMuWLc.annotations.xml\n",
      "[info] 16 aa-SLTMuWLc.description <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-SLTMuWLc.description\n",
      "[info] 17 aa-SLTMuWLc.dllog <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-SLTMuWLc.dllog\n",
      "[info] 18 aa-SLTMuWLc.info.json <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-SLTMuWLc.info.json\n",
      "[info] 19 aa-SLTMuWLc.mp4 <- pipe:curl https://storage.googleapis.com/lpr-yt8m/aa-SLTMuWLc.mp4\n"
     ]
    }
   ],
   "source": [
    "!tarp create --count=20 shards/shard-000000.txt -o shards/shard-000000.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharding in Parallel\n",
    "\n",
    "If you want to shard in parallel, you probably want to run many of these jobs in parallel, and you don't what to store data locally. You can store both the source .txt files and the output .tar files in the cloud and use a command like this:\n",
    "\n",
    "```Bash\n",
    "gsutil cat gs://bucket/shard-$shard.txt |\n",
    "tarp create - -o - |\n",
    "gsutil cp - gs://bucket/shard-$shard.tar\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
